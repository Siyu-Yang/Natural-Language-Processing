{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EECS 498 - Assignment 2 - languageIdentification.py\n",
    "### By: Alexander \"AJ\" Goldstein - uniquename: ajva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from __future__ import division\n",
    "from operator import add, sub\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing Functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) read in and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input 1: dataFile (string) - name of data file\n",
    "# output 1: alphabet (dict) - unique dataFile characters (as keys) and their assigned alphaKey (as values)\n",
    "# output 2: fiveCharAlphas (dict) - five character sequences (as keys) and their alphaKeys (as values)\n",
    "# output 3: fiveCharLabels (dict) - five character sequences (as keys) and their languageCode (as values)\n",
    "\n",
    "def read_in_and_process_data(dataFile, alphabet, fiveCharAlphas):\n",
    "    \n",
    "    # create dictionaries and variables for tracking pre-processing\n",
    "    sentenceSeqs = {}\n",
    "    sentenceLabels = {}\n",
    "    fiveCharLabels = {}\n",
    "    alphaCount = len(alphabet.keys())\n",
    "    \n",
    "    with open(dataFile) as data:\n",
    "        for line in data:\n",
    "            fiveCharSeqs = []\n",
    "            language, space, sentence = line.partition(' ')\n",
    "            \n",
    "            # generate language encoding\n",
    "            languageCode = []\n",
    "            if language == 'ENGLISH':\n",
    "                languageCode = [1,0,0]\n",
    "            elif language == 'ITALIAN':\n",
    "                languageCode = [0,1,0]\n",
    "            elif language == 'FRENCH':\n",
    "                languageCode = [0,0,1]\n",
    "                \n",
    "            # store new characters in alphabet dictionary\n",
    "            for char in sentence:\n",
    "                if (char not in alphabet):\n",
    "                    alphabet[char] = alphaCount\n",
    "                    alphaCount += 1\n",
    "            \n",
    "            # create & store five character sequences (w/ languageKeys & alphaKeys)\n",
    "            for idx, char in enumerate(sentence):\n",
    "\n",
    "                # create five char sequence\n",
    "                if (idx + 5 <= len(sentence)):\n",
    "                    fiveChars = sentence[idx:idx+5]\n",
    "                    fiveCharSeqs.append(fiveChars)\n",
    "\n",
    "                    # generate sequence alphaKeys\n",
    "                    alphaKeys = []\n",
    "                    for singleChar in fiveChars:\n",
    "                        alphaKeys.append(alphabet[singleChar])\n",
    "\n",
    "                    # store alphaKeys and language\n",
    "                    fiveCharAlphas[fiveChars] = alphaKeys\n",
    "                    fiveCharLabels[fiveChars] = languageCode\n",
    "                    \n",
    "            # store fiveCharSeqs into sentenceSeqs before selecting new sentence\n",
    "            sentenceSeqs[sentence] = fiveCharSeqs\n",
    "            sentenceLabels[sentence] = languageCode\n",
    "                \n",
    "    return alphabet, sentenceSeqs, sentenceLabels, fiveCharAlphas, fiveCharLabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) process TEST data (slightly different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input 1: dataFile (string) - name of data file\n",
    "# output 1: alphabet (dict) - unique dataFile characters (as keys) and their assigned alphaKey (as values)\n",
    "# output 2: fiveCharAlphas (dict) - five character sequences (as keys) and their alphaKeys (as values)\n",
    "# output 3: fiveCharLabels (dict) - five character sequences (as keys) and their languageCode (as values)\n",
    "\n",
    "def process_test_data(dataFile, solutionsFile, alphabet, fiveCharAlphas):\n",
    "    \n",
    "    # create dictionaries and variables for tracking pre-processing\n",
    "    sentenceSeqs = {}\n",
    "    sentenceLabels = {}\n",
    "    fiveCharLabels = {}\n",
    "    alphaCount = len(alphabet.keys())\n",
    "    \n",
    "    with open(dataFile) as data:\n",
    "        with open(solutionsFile) as sol:\n",
    "            for sentence, solLine in zip(data, sol):\n",
    "                \n",
    "                # set new storage\n",
    "                fiveCharSeqs = []\n",
    "                languageCode = []\n",
    "                \n",
    "                # get language from solutions\n",
    "                lineNum, space, language = solLine.partition(' ')\n",
    "                if language == 'English\\n':\n",
    "                    languageCode = [1,0,0]\n",
    "                elif language == 'Italian\\n':\n",
    "                    languageCode = [0,1,0]\n",
    "                elif language == 'French\\n':\n",
    "                    languageCode = [0,0,1]  \n",
    "                \n",
    "                # store new characters in alphabet dictionary\n",
    "                for char in sentence:\n",
    "                    if (char not in alphabet):\n",
    "                        alphabet[char] = alphaCount\n",
    "                        alphaCount += 1\n",
    "\n",
    "                # create & store five character sequences (w/ languageKeys & alphaKeys)\n",
    "                for idx, char in enumerate(sentence):\n",
    "\n",
    "                    # create five char sequence\n",
    "                    if (idx + 5 <= len(sentence)):\n",
    "                        fiveChars = sentence[idx:idx+5]\n",
    "                        fiveCharSeqs.append(fiveChars)\n",
    "\n",
    "                        # generate sequence alphaKeys\n",
    "                        alphaKeys = []\n",
    "                        for singleChar in fiveChars:\n",
    "                            alphaKeys.append(alphabet[singleChar])\n",
    "\n",
    "                        # store alphaKeys and language\n",
    "                        fiveCharAlphas[fiveChars] = alphaKeys\n",
    "                        fiveCharLabels[fiveChars] = languageCode\n",
    "\n",
    "                # store fiveCharSeqs into sentenceSeqs before selecting new sentence\n",
    "                sentenceSeqs[sentence] = fiveCharSeqs\n",
    "                sentenceLabels[sentence] = languageCode\n",
    "                \n",
    "    return alphabet, sentenceSeqs, sentenceLabels, fiveCharAlphas, fiveCharLabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) one-hot-encode five character sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input 1: fiveCharAlphas (dict) - five character sequences (as keys) and their alphaKeys (as values)\n",
    "# output 1: fiveCharEncodings (dict) - five character sequences (as keys) and their ONE-HOT ENCODINGS (as values)\n",
    "\n",
    "def one_hot_encode_sequences(fiveCharAlphas):\n",
    "    \n",
    "    # create dictionary for encoding storage\n",
    "    fiveCharEncodings = {}\n",
    "    \n",
    "    # fit encoder to given five character sequences\n",
    "    enc = OneHotEncoder()\n",
    "    enc.fit(fiveCharAlphas.values())\n",
    "    \n",
    "    # generate one-hot-encodings for every five character sequence\n",
    "    for sequence, alphaKeys in fiveCharAlphas.items():\n",
    "        encoding = enc.transform([alphaKeys]).todense()\n",
    "        fiveCharEncodings[sequence] = encoding\n",
    "    \n",
    "    return fiveCharEncodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Functions: Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) initialize weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize weight & bias matrices\n",
    "def initialize_weights_and_biases(inputSize, hiddenSize, outputSize):\n",
    "    weights1 = np.array([[np.random.uniform(low=(-1.0), high=(1.0)) for y in range(inputSize)] for x in range(hiddenSize)])\n",
    "    weights2 = np.array([[np.random.uniform(low=(-1.0), high=(1.0)) for y in range(hiddenSize)] for x in range(outputSize)])\n",
    "    biases1 = np.array([np.random.uniform(low=(-1.0), high=(1.0)) for y in range(hiddenSize)])\n",
    "    biases2 = np.array([np.random.uniform(low=(-1.0), high=(1.0)) for y in range(outputSize)])\n",
    "    \n",
    "    return weights1, weights2, biases1, biases2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) forward propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-1*z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate hidden layer from input layer using sigmoid function\n",
    "def calculate_hidden_layer(x, W1, b1):\n",
    "    h_prime = np.array(map(add, np.dot(W1,x.T), b1))\n",
    "    h = np.array(map(sigmoid, h_prime))\n",
    "    h = h.reshape(h.shape[0], 1)\n",
    "    return h, h_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(y):\n",
    "    return np.exp(y)/(np.exp(y).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_output_layer(h, W2, b2):\n",
    "    y_prime = map(add, np.dot(W2,h), b2)\n",
    "    y_pred = np.array(softmax(y_prime))\n",
    "    y_pred = y_pred.reshape(y_pred.shape[0])\n",
    "    return y_pred, y_prime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) backpropogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_squared_loss(y_pred, y_true):\n",
    "    return 0.5*(pow(y_pred - y_true,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax_grad(s):\n",
    "    s = s.reshape(-1,1)\n",
    "    s_ = s.reshape(1,-1)\n",
    "    return np.diagflat(s_) - np.dot(s, s.T)\n",
    "\n",
    "def loss_sqr_grad(y_pred, y_true):\n",
    "    return y_pred - y_true\n",
    "\n",
    "def loss_sqr_softmax_grad(y_pred, y_true):\n",
    "    return np.dot(loss_sqr_grad(y_pred, y_true).T, softmax_grad(y_pred)).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backpropogation(x, h_prime, h, y_prime, y_pred, y_true, W1, W2):\n",
    "    \n",
    "    # output to hidden layer\n",
    "    y_prime_loss = loss_sqr_softmax_grad(y_pred, y_true)\n",
    "    \n",
    "    # hidden layer\n",
    "    W2_loss = np.dot(y_prime_loss,h.T)\n",
    "    b2_loss = y_prime_loss\n",
    "    h_loss = np.dot(W2.T,y_prime_loss)\n",
    "    \n",
    "    h_prime_loss = np.multiply(h_loss, np.multiply(h, (1.0-h)))\n",
    "    \n",
    "    # hidden layer to input layer\n",
    "    W1_loss = np.dot(h_prime_loss,x)\n",
    "    b1_loss = h_prime_loss\n",
    "    x_loss = np.dot(W1.T,h_prime_loss)\n",
    "    \n",
    "    # make small reshapes\n",
    "    b2_loss = np.array(b2_loss)\n",
    "    b2_loss = b2_loss.reshape(b2_loss.shape[0])\n",
    "    b1_loss = b1_loss.reshape(b1_loss.shape[0])\n",
    "    \n",
    "    return W1_loss, W2_loss, b1_loss, b2_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(learningRate, W1, W2, b1, b2, W1_loss, W2_loss, b1_loss, b2_loss):\n",
    "    \n",
    "    # theta_new = theta_old - rate*loss\n",
    "    W1_new = W1 - learningRate*W1_loss\n",
    "    W2_new = W2 - learningRate*W2_loss\n",
    "    b1_new = b1 - learningRate*b1_loss\n",
    "    b2_new = b2 - learningRate*b2_loss\n",
    "    \n",
    "    return W1_new, W2_new, b1_new, b2_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Functions: Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) calculate NN accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: replace sentenceSeqs with sentenceSeqs before official running!!\n",
    "\n",
    "def calculate_NN_accuracy(sentenceSeqs, sentenceLabels, fiveCharEncodings, fiveCharLabels, W1, W2, b1, b2):\n",
    "    \n",
    "    # storage for each prediction\n",
    "    predictions = {} # {sentence:languagePredict}\n",
    "    predictOutcomes = [] #True/False for each prediction\n",
    "    \n",
    "    # loop through all the sentences\n",
    "    for sentence, fiveCharSeqs in sentenceSeqs.items():\n",
    "        sentencePredTotals = [0,0,0]\n",
    "        \n",
    "        # run the neural network on one five character sequence at a time\n",
    "        for fiveChars in fiveCharSeqs:\n",
    "    \n",
    "            # generate input, hidden, and output layers\n",
    "            x = np.array(fiveCharEncodings[fiveChars])\n",
    "            h, h_prime = calculate_hidden_layer(x, W1, b1)\n",
    "            y_pred, y_prime = calculate_output_layer(h, W2, b2)\n",
    "\n",
    "            # add on current sequence prediction\n",
    "            sentencePredTotals += y_pred\n",
    "    \n",
    "        # get true language for current sentence\n",
    "        y_true = sentenceLabels[sentence]\n",
    "        \n",
    "        # check sentence prediction accuracy via majority vote of five character sequences\n",
    "        # check for True or False prediction outcome\n",
    "        predLang = np.argmax(sentencePredTotals)\n",
    "        trueLang = y_true.index(max(y_true))\n",
    "        predictOutcomes.append(True) if predLang == trueLang else predictOutcomes.append(False)\n",
    "        \n",
    "        # store language prediction\n",
    "        langPredicted = ''\n",
    "        if predLang == 0:\n",
    "            langPredicted = 'English'\n",
    "        elif predLang == 1:\n",
    "            langPredicted = 'Italian'\n",
    "        elif predLang == 2:\n",
    "            langPredicted = 'French'\n",
    "        predictions[sentence] = langPredicted\n",
    "        \n",
    "    # calculate overall accuracy of this run through\n",
    "    accuracy = sum(predictOutcomes)/len(predictOutcomes)\n",
    "    print(\"accuracy:\",accuracy)\n",
    "    \n",
    "    return accuracy, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) train NN weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: replace sentenceSeqs with sentenceSeqs before official running!!\n",
    "\n",
    "def train_neural_net(sentenceSeqs, fiveCharEncodings, fiveCharLabels, learningRate, W1, W2, b1, b2):\n",
    "    \n",
    "    fiveCharSeqs = list(fiveCharLabels.keys())\n",
    "    shuffle(fiveCharSeqs)\n",
    "\n",
    "    # run the neural network on one RANDOM five character sequence at a time\n",
    "    for fiveChars in fiveCharSeqs:\n",
    "\n",
    "        # generate input, hidden, and output layers\n",
    "        x = np.array(fiveCharEncodings[fiveChars])\n",
    "        h, h_prime = calculate_hidden_layer(x, W1, b1)\n",
    "        y_pred, y_prime = calculate_output_layer(h, W2, b2)\n",
    "\n",
    "        # get true language for current sentence\n",
    "        y_true = fiveCharLabels[fiveChars]\n",
    "        loss = calculate_squared_loss(y_pred, y_true)\n",
    "\n",
    "        # conduct backpropogation\n",
    "        W1_loss, W2_loss, b1_loss, b2_loss = backpropogation(x, h_prime, h, y_prime, y_pred, y_true, W1, W2)\n",
    "\n",
    "        # use gradient descent to update weights with backpropogation gradients\n",
    "        W1, W2, b1, b2 = gradient_descent(learningRate, W1, W2, b1, b2, W1_loss, W2_loss, b1_loss, b2_loss)\n",
    "    \n",
    "    # return new weights\n",
    "    return W1, W2, b1, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) run the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: replace sentenceSeqs with sentenceSeqs before official running!!\n",
    "\n",
    "def run_neural_net(sentenceSeqs_t, sentenceLabels_t, fiveCharLabels_t, \n",
    "                   sentenceSeqs_d, sentenceLabels_d, fiveCharLabels_d, \n",
    "                   fiveCharEncodings, learningRate, hiddenSize, outputSize = 3):\n",
    "    \n",
    "    # set runCount and create accuracy storage\n",
    "    runCount = 1\n",
    "    NN_Accuracies = []\n",
    "    \n",
    "    # set inputSize, randomly initialize weights\n",
    "    inputSize = fiveCharEncodings.values()[0].shape[1]\n",
    "    W1, W2, b1, b2 = initialize_weights_and_biases(inputSize, hiddenSize, outputSize)\n",
    "    \n",
    "    # calculate & store starting accuracy on the train & dev data\n",
    "    startTrainAcc, predictions = calculate_NN_accuracy(sentenceSeqs_t, sentenceLabels_t, fiveCharEncodings, fiveCharLabels_t, W1, W2, b1, b2)\n",
    "    startDevAcc, predictions = calculate_NN_accuracy(sentenceSeqs_d, sentenceLabels_d, fiveCharEncodings, fiveCharLabels_d, W1, W2, b1, b2)\n",
    "    NN_Accuracies.append([startTrainAcc, startDevAcc])\n",
    "    \n",
    "    while runCount <= 3:\n",
    "        print(\"runCount =\",runCount)\n",
    "        \n",
    "        # train neural net weights\n",
    "        W1, W2, b1, b2 = train_neural_net(sentenceSeqs_t, fiveCharEncodings, fiveCharLabels_t, learningRate, W1, W2, b1, b2)\n",
    "        \n",
    "        # calculate & store accuracy with updated weights\n",
    "        trainAccuracy, predictions = calculate_NN_accuracy(sentenceSeqs_t, sentenceLabels_t, fiveCharEncodings, fiveCharLabels_t, W1, W2, b1, b2)\n",
    "        devAccuracy, predictions = calculate_NN_accuracy(sentenceSeqs_d, sentenceLabels_d, fiveCharEncodings, fiveCharLabels_d, W1, W2, b1, b2)\n",
    "        NN_Accuracies.append([trainAccuracy, devAccuracy])\n",
    "        \n",
    "        # index runCount\n",
    "        runCount += 1\n",
    "    \n",
    "    # return all accuracies & final NN weights\n",
    "    return NN_Accuracies, W1, W2, b1, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize Hyperparameters Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize_hyperparameters(sentenceSeqs_t, sentenceLabels_t, fiveCharLabels_t, \n",
    "                                 sentenceSeqs_d, sentenceLabels_d, fiveCharLabels_d,\n",
    "                                     sentenceSeqs_TEST, sentenceLabels_TEST, fiveCharLabels_TEST, \n",
    "                                         fiveCharEncodings,  outputSize = 3):\n",
    "    \n",
    "    # 0) select at least 5 different sets of hyperparameter values\n",
    "    hyperparams = []\n",
    "    hyperparams.append([50,1.0])\n",
    "    hyperparams.append([50,10.0])\n",
    "    hyperparams.append([200,1.0])\n",
    "    hyperparams.append([200,10.0])\n",
    "    hyperparams.append([100,1.0])\n",
    "\n",
    "    # 2) see which performs best on the dev data\n",
    "    bestAccuracy = 0\n",
    "    bestParams = []\n",
    "    bestWeights = []\n",
    "\n",
    "    for param in hyperparams:\n",
    "        hiddenSize = param[0]\n",
    "        learningRate = param[1]\n",
    "\n",
    "        # set inputSize, randomly initialize weights\n",
    "        inputSize = fiveCharEncodings.values()[0].shape[1]\n",
    "        W1, W2, b1, b2 = initialize_weights_and_biases(inputSize, hiddenSize, outputSize = 3)\n",
    "\n",
    "        # train network on the training data\n",
    "        W1, W2, b1, b2 = train_neural_net(sentenceSeqs_t, fiveCharEncodings, fiveCharLabels_t, learningRate, W1, W2, b1, b2)\n",
    "\n",
    "        # test on the dev data\n",
    "        devAccuracy, predictions = calculate_NN_accuracy(sentenceSeqs_d, sentenceLabels_d, fiveCharEncodings, fiveCharLabels_d, W1, W2, b1, b2)\n",
    "\n",
    "        # update best accuracy and parameters\n",
    "        if devAccuracy > bestAccuracy:\n",
    "            bestAccuracy = devAccuracy\n",
    "            bestParams = [hiddenSize, learningRate]\n",
    "            bestWeights = [W1, W2, b1, b2]\n",
    "\n",
    "    # 3) use best hyperparameters to calculate accuracy on test data\n",
    "    W1_best = bestWeights[0]\n",
    "    W2_best = bestWeights[1]\n",
    "    b1_best = bestWeights[2]\n",
    "    b2_best = bestWeights[3]\n",
    "\n",
    "    testAccuracy, predictions = calculate_NN_accuracy(sentenceSeqs_TEST, sentenceLabels_TEST,\n",
    "                                                      fiveCharEncodings, fiveCharLabels_TEST,\n",
    "                                                      W1_best, W2_best, b1_best, b2_best)\n",
    "\n",
    "    return testAccuracy, bestParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SCRIPT NOTE: switch out arguments\n",
    "# read in file names\n",
    "trainFile = \"languageIdentification.data/train\"\n",
    "devFile = \"languageIdentification.data/dev\"\n",
    "testFile = \"languageIdentification.data/test\"\n",
    "\n",
    "#trainFile = sys.argv[1]\n",
    "#devFile = sys.argv[2]\n",
    "#testFile = sys.argv[3]\n",
    "\n",
    "testSolFile = \"languageIdentification.data/test_solutions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in and process trainFile, devFile, testFile\n",
    "alphabet = {}\n",
    "fiveCharAlphas = {}\n",
    "alphabet, sentenceSeqs_t, sentenceLabels_t, fiveCharAlphas, fiveCharLabels_t = read_in_and_process_data(trainFile, alphabet, fiveCharAlphas)\n",
    "alphabet, sentenceSeqs_d, sentenceLabels_d, fiveCharAlphas, fiveCharLabels_d = read_in_and_process_data(devFile, alphabet, fiveCharAlphas)\n",
    "alphabet, sentenceSeqs_TEST, sentenceLabels_TEST, fiveCharAlphas, fiveCharLabels_TEST = process_test_data(testFile, testSolFile, alphabet, fiveCharAlphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomSampleDict(dictionary, size):\n",
    "    dictionary_keys = dictionary.keys()[:size]\n",
    "    shuffle(dictionary_keys)\n",
    "    dictionary_vals = dictionary.values()[:size]\n",
    "    shuffle(dictionary_vals)\n",
    "    dictionary = dict(zip(dictionary_keys, dictionary_vals))\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentenceSeqs_t = randomSampleDict(sentenceSeqs_t, 20)\n",
    "sentenceSeqs_d = randomSampleDict(sentenceSeqs_d, 20)\n",
    "#sentenceSeqs_TEST = randomSampleDict(sentenceSeqs_TEST, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# encode five character sequences\n",
    "fiveCharEncodings = one_hot_encode_sequences(fiveCharAlphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0) set hyperparameters\n",
    "hiddenSize = 100\n",
    "learningRate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy:', 0.3)\n",
      "('accuracy:', 0.3)\n",
      "('runCount =', 1)\n",
      "('accuracy:', 0.35)\n",
      "('accuracy:', 0.35)\n",
      "('runCount =', 2)\n",
      "('accuracy:', 0.4)\n",
      "('accuracy:', 0.4)\n",
      "('runCount =', 3)\n",
      "('accuracy:', 0.35)\n",
      "('accuracy:', 0.35)\n"
     ]
    }
   ],
   "source": [
    "# run neural network (for 3 epochs), calculate accuracies and weights/biases\n",
    "NN_Accuracies, W1, W2, b1, b2 = run_neural_net(sentenceSeqs_t, sentenceLabels_t, fiveCharLabels_t, \n",
    "                                               sentenceSeqs_d, sentenceLabels_d, fiveCharLabels_d, \n",
    "                                               fiveCharEncodings, learningRate, hiddenSize, outputSize = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS/4f10u1krwecMQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11399bd10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracies\n",
    "train_accuracies = [0,0,0,0]\n",
    "dev_accuracies = [0,0,0,0]\n",
    "for idx, accuracy in enumerate(NN_Accuracies):\n",
    "    train_accuracies[idx] = NN_Accuracies[idx][0]\n",
    "    dev_accuracies[idx] = NN_Accuracies[idx][1]\n",
    "\n",
    "plt.plot([0,1,2,3], train_accuracies, 'b-', label='train')\n",
    "plt.plot([0,1,2,3], dev_accuracies, 'r-', label='dev')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('epoch #')\n",
    "plt.ylabel('accuracy')\n",
    "plt.savefig('accuracy.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy:', 0.9697986577181208)\n",
      "('testAccuracy:', 0.9697986577181208)\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy on test data\n",
    "testAccuracy, predictions = calculate_NN_accuracy(sentenceSeqs_TEST, sentenceLabels_TEST, fiveCharEncodings, fiveCharLabels_TEST, W1, W2, b1, b2)\n",
    "print(\"testAccuracy:\", testAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# produce predictions output file\n",
    "output = \"languageIdentificationPart1.output\"\n",
    "f = open(output, \"w\")\n",
    "\n",
    "for sentence, language in predictions.items():\n",
    "    f.write(sentence.rstrip() + ' ' + language + '\\n')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy:', 0.35)\n",
      "('accuracy:', 0.45)\n",
      "('accuracy:', 0.45)\n",
      "('accuracy:', 0.3)\n",
      "('accuracy:', 0.3)\n",
      "('accuracy:', 0.33221476510067116)\n",
      "Best Performing Hyperparameters: hiddenSize: 50 learningRate: 10.0\n",
      "Accuracy of best language identifier: 0.332214765101\n"
     ]
    }
   ],
   "source": [
    "# optimize hyperparameters\n",
    "# return optimal accuracy and best hyperparameters\n",
    "optimalAccuracy, bestParams = optimize_hyperparameters(sentenceSeqs_t, sentenceLabels_t, fiveCharLabels_t, \n",
    "                                 sentenceSeqs_d, sentenceLabels_d, fiveCharLabels_d,\n",
    "                                     sentenceSeqs_TEST, sentenceLabels_TEST, fiveCharLabels_TEST, \n",
    "                                         fiveCharEncodings,  outputSize = 3)\n",
    "\n",
    "print(\"Best Performing Hyperparameters: \" + \"hiddenSize: \" + str(bestParams[0]) + \" learningRate: \" + str(bestParams[1]))\n",
    "print(\"Accuracy of best language identifier: \" + str(optimalAccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
