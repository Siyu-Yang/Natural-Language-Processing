{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EECS 498 - Assignment 1 - SBD.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Major Task:</span> write a Python program SBD.py that detects sentence boundaries in text.\n",
    "\n",
    "### <span style=\"color:red\">Result:</span> built a program that predicts if a period (.) is the end of a sentence or not with 99.2% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Read in & process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "file1 = sys.argv[1]\n",
    "file2 = sys.argv[2]\n",
    "\n",
    "file1 = 'SBD.train'\n",
    "file2 = 'SBD.test'\n",
    "\n",
    "with open(file1) as train:\n",
    "    trainFile = train.read()\n",
    "with open(file2) as test:\n",
    "    testFile = test.read()\n",
    "    \n",
    "trainData = pd.read_csv(trainFile, header=None,delimiter=r\"\\s+\", quoting=csv.QUOTE_NONE)\n",
    "testData = pd.read_csv(testFile, header=None,delimiter=r\"\\s+\", quoting=csv.QUOTE_NONE)\n",
    "\n",
    "\n",
    "# save period indices, fix labels\n",
    "testData.columns = ['line', 'word', 'label']\n",
    "savedTest = testData\n",
    "testData = testData.drop('line', 1)\n",
    "\n",
    "# fix train column labels\n",
    "trainData.columns = ['line', 'word', 'label']\n",
    "trainData = trainData.drop('line', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Create Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Extract the following features from the data for each instance of a '.' with an NEOS/EOS label:\n",
    "\n",
    "## -------- core features -----------\n",
    "## L - word to the left of the '.'\n",
    "## R - word to the right of the '.'\n",
    "## LLENGTH - length of L is less than 3 (bool)\n",
    "## LCAP - L is capitalized (bool)\n",
    "## RCAP - R is capitalized (bool)\n",
    "\n",
    "## ----- my self-selected features ------\n",
    "## LALLCAPS - L is all capital letters (bool)\n",
    "## RQUOTE - R is a quotation (\") mark (bool)\n",
    "## RLENGTH - length of R is less than 5 (bool)\n",
    "\n",
    "def get_features_and_labels(data):\n",
    "    \n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        if (data.loc[index, 'label'] == 'EOS') or (data.loc[index, 'label'] == 'NEOS'):\n",
    "\n",
    "            features_dict = {}\n",
    "\n",
    "            # 5 core features\n",
    "            left = data.loc[index, 'word'][:-1] # remove trailing period\n",
    "            right = data.loc[index+1, 'word'] if (index != len(data)-1) else 'LAST' # check for last line\n",
    "            lLength = True if (len(left) < 3) else False\n",
    "            lCap = True if ((len(left) > 0) and (left[0].isupper())) else False\n",
    "            rCap = True if ((right != 'LAST') and (right[0].isupper())) else False\n",
    "\n",
    "            # 3 self-chosen features\n",
    "            lAllCaps = True if ((len(left) > 0) and (left.isupper())) else False\n",
    "            rQuote = True if (right == '\"') else False\n",
    "            rLength = True if ((right != 'LAST') and (len(right) < 5)) else False\n",
    "\n",
    "            # Store Features in Dictionary\n",
    "            features_dict['LEFT'] = left\n",
    "            features_dict['RIGHT'] = right\n",
    "            features_dict['LLENGTH'] = lLength\n",
    "            features_dict['LCAP'] = lCap\n",
    "            features_dict['RCAP'] = rCap\n",
    "            features_dict['LALLCAPS'] = lAllCaps\n",
    "            features_dict['RQUOTE'] = rQuote\n",
    "            features_dict['RLENGTH'] = rLength\n",
    "\n",
    "            # Store Features & Labels in lists\n",
    "            features_list.append(features_dict)\n",
    "            labels_list.append(data.loc[index, 'label'])\n",
    "    \n",
    "    return features_list, labels_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Implement Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_decision_tree():\n",
    "    \n",
    "    # extract features and labels from train & test data\n",
    "    X_train, Y_train = get_features_and_labels(trainData)\n",
    "    X_test, Y_test = get_features_and_labels(testData)\n",
    "    \n",
    "    # encode features & labels\n",
    "    dictVec = DictVectorizer()\n",
    "    labelEn = LabelEncoder()    \n",
    "    X_train = dictVec.fit_transform(X_train) # NOTE: train data = fit.transform\n",
    "    Y_train = labelEn.fit_transform(Y_train)\n",
    "    X_test = dictVec.transform(X_test) # NOTE: test data = transform\n",
    "    Y_test = labelEn.transform(Y_test)\n",
    "    \n",
    "    entropy_clf = DecisionTreeClassifier(criterion = \"entropy\")\n",
    "    entropy_clf.fit(X_train, Y_train)\n",
    "    Y_predict = entropy_clf.predict(X_test)\n",
    "    \n",
    "    # print accuracy\n",
    "    print \"Accuracy is \", accuracy_score(Y_test,Y_predict)*100\n",
    "    \n",
    "    # return predictions\n",
    "    return Y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  99.1875746714\n"
     ]
    }
   ],
   "source": [
    "Y_predict = build_decision_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def generate_output():\n",
    "\n",
    "    # insert in prediction labels to original test data\n",
    "#    indexList = savedTest.index[(savedTest['label'] == 'NEOS') or (savedTest['label'] == 'EOS')].tolist()\n",
    "#    count = 0\n",
    "#    for index in enumerate(savedTest['label']):\n",
    "#        if ((label == 'NEOS') or (label == 'EOS')):\n",
    "#            savedTest[index] = Y_predict[count]\n",
    "#            count += 1\n",
    "#    \n",
    "#    # output predictions into txt file\n",
    "#    np.savetxt(r'SBD.test.out', savedTest.values, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:si370]",
   "language": "python",
   "name": "conda-env-si370-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
